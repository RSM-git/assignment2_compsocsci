{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "> **Exercise 1: Mixing Patterns and Assortativity.**\n",
    ">\n",
    "> * For each node, compute the fraction of edges that connect to a node that works in the same top field. Find the average value across all nodes.\n",
    "> * Create a new graph, with the same nodes and edges, but where the association between nodes and field is shuffled. Compute the measure above for this randomized graph.\n",
    "> * Repeat the point above 100 times (at least). Plot the distribution of the values obtained and compare it with the value you have found for the real graph. Is the chance to connect to a member of the same field significantly higher than it would be by chance?\n",
    "> * Compute the assortativity coefficient with respect to author's field. How do you interpret the value you obtain? (__Hint__: See [this paper](https://nbviewer.org/github/suneman/socialgraphs2019/blob/master/lectures/Week5.ipynb), eq (2)). **Important**: here I do not want you to use the NetworkX implementation, but rather to implement your own version of the measure.\n",
    "> * Is the graph assortative with respect to the degree? (e.g. do high-degree scientists tend to link to other high-degree scientists, and low-degree scientists to other low-degree scientists?). Provide an interpretation of your answer.\n",
    "> * _Optional:_ Estimate the gender of each author from their name, using the [World Gender Name Dictionary](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/MSEGSJ). Repeat the analysis above to study the assortativity of the network by gender rather than by field. What do you observe?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import requests as rq\n",
    "from semanticscholar import SemanticScholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "authors = pd.read_csv('all_authors.csv', index_col=0)\n",
    "papers = pd.read_csv('all_papers.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'None'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_23352/4048222097.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mpaperindex\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpapers\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m         \u001B[0mpaper\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpapers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpaperindex\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'authors'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m         \u001B[0mpaper_authors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mpaper\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreplace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"'\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m\"\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\",\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mid\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpaper_authors\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m             \u001B[1;31m# drop paper from dataframe so we don't recount it\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: invalid literal for int() with base 10: 'None'"
     ]
    }
   ],
   "source": [
    "\n",
    "# import author data\n",
    "# We have a mistake in the data, so each author only has their top field listed\n",
    "# {\"id1\" = 123123123,\"id2\" = 123123123, \"weight\" = 3\"}\n",
    "\n",
    "# list of dicts with authorid 1 and authorid 2 and how many times they coauthored each other\n",
    "edgelist = []\n",
    "for id in authors[\"id\"]:\n",
    "    for paperindex in range(len(papers)):\n",
    "        paper = papers.iloc[paperindex]['authors']\n",
    "        paper_authors = list(map(int,paper[1:-1].replace(\"'\",\"\").split(\",\")))\n",
    "        if id in paper_authors:\n",
    "            # drop paper from dataframe so we don't recount it\n",
    "            papers.drop(paperindex, inplace=True)\n",
    "            for author in paper_authors:\n",
    "                if author != id:\n",
    "                    for dic in edgelist:\n",
    "                        if dic[\"id1\"] == id and dic[\"id2\"] == author:\n",
    "                            dic[\"weight\"] += 1\n",
    "                        elif dic[\"id1\"] == author and dic[\"id2\"] == id:\n",
    "                            dic[\"weight\"] += 1\n",
    "                        else:\n",
    "                            edgelist.append({\"id1\": id, \"id2\": author, \"weight\": 1})\n",
    "\n",
    "edgelist\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s = \"k√¶asjdakbd123123,,,,123\"\n",
    "s.replace([\"],\"\").split(\"123\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
